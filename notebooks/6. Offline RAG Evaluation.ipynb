{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63662267-6237-4db3-be13-c95b6c3780be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SSL_CERT_FILE\"] = \"/mnt/d/Travel Assistant/Musafir/Fortinet_CA_SSL(15).cer\"\n",
    "os.environ[\"REQUESTS_CA_BUNDLE\"] = \"/mnt/d/Travel Assistant/Musafir/Fortinet_CA_SSL(15).cer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62e9bbc0-1e10-437f-aa15-ac84504c5866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Travel Assistant/Musafir/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "import requests\n",
    "from fastembed import TextEmbedding\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bc0937b-4369-4bf2-be6e-da9e1c7dc59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a88f34f-a36c-4f37-93c1-322e2169adcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data \n",
    "with open('../data/processed_data/documents-with-ids.json', 'rt') as f_in:\n",
    "    documents = json.load(f_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d294eebb-aa02-42d9-921e-370fb9f52fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground Truth data\n",
    "df_gt = pd.read_csv('../data/result/groud-truth-retrieval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce6b19bc-5b80-4edb-a1c9-9362ef81142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth =  df_gt.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df619b09-470a-4f34-8acf-8664f09b89b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '91c82200',\n",
       " 'city': 'Cairo',\n",
       " 'question': 'What was the purpose of Abdeen Palace in Cairo until 1952?'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e0d0eef-d9f2-40dc-9a1f-6681f414b1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'30.0417 31.2483 4 Abdeen Palace . About 1 km east of Midan El-Tahrir, it was the royal residence until the Egyptian monarchy was deposed in 1952. ( updated Jan 2018 )'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_idx = {d['id']: d for d in documents}\n",
    "doc_idx['91c82200']['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb45fc1b-d844-4afe-b1af-22cac4110677",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'multi-qa-distilbert-cos-v1'\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8868dd19-5c8d-4442-8136-fce6d7aa74bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False, 'architecture': 'DistilBertModel'})\n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "820d2a96-6d13-40e8-9939-e53479c051fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8543/2923977033.py:2: UserWarning: Qdrant client version 1.15.1 is incompatible with server version 1.12.4. Major versions should match and minor version difference must not exceed 1. Set check_compatibility=False to skip version check.\n",
      "  qdrant_client = QdrantClient(url=\"http://localhost:6333\")\n"
     ]
    }
   ],
   "source": [
    "#connecting to local Qdrant instance\n",
    "qdrant_client = QdrantClient(url=\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c6e6dbc-8946-497b-baab-a1732aa1dbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rrf_search(query: str, limit: int = 5) -> list[models.ScoredPoint]:\n",
    "    results = qdrant_client.query_points(\n",
    "        collection_name=\"traveller-dense-and-sparse\",\n",
    "        prefetch=[\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=query,\n",
    "                    model=\"jinaai/jina-embeddings-v2-small-en\",\n",
    "                ),\n",
    "                using=\"jina-small\",\n",
    "                limit=(5 * limit),\n",
    "            ),\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=query,\n",
    "                    model=\"Qdrant/bm25\",\n",
    "                ),\n",
    "                using=\"bm25\",\n",
    "                limit=(1 * limit),\n",
    "            ),\n",
    "        ],\n",
    "        query=models.FusionQuery(fusion=models.Fusion.RRF),\n",
    "        with_payload=True,\n",
    "    )\n",
    "\n",
    "    return results.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb195ffa-6f17-4026-bcd3-d761389c7f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai import Mistral\n",
    "from mistralai.models import UserMessage\n",
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5bd5115-2a4e-4dd2-b358-ea8d11323019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loads variables from .env\n",
    "load_dotenv()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64b5b337-3de0-4872-8517-3e4cd3a2cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63ae2908-0ea0-4161-b11c-24d1798d5fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_client = Mistral(api_key = api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a0f38d4-3bf6-40fe-99a4-30d1d20479d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    context_template = \"Q: {question}\\n A: {text}\"\n",
    "\n",
    "    context_parts = []\n",
    "    for point in search_results: \n",
    "        payload = point.payload\n",
    "        context_parts.append(\n",
    "            context_template.format(\n",
    "                question=query,\n",
    "                text=payload.get(\"text\", \"\")\n",
    "            )\n",
    "        )\n",
    "\n",
    "    context = \"\\n\\n\".join(context_parts)\n",
    "    \n",
    "    prompt_template = \"\"\"\n",
    "You're a travel assistant. Answer the QUESTION based on the CONTEXT from the traveller database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION. If the QUESTION doesn't have a CONTEXT in the data just mention\n",
    "you cannot answer the question.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "    \"\"\".strip()\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context)\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a7b8f4cf-1c0f-4b0e-a579-6f5838ea55a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = llm_client.chat.complete(\n",
    "        model= \"mistral-medium-2508\",\n",
    "        messages=[UserMessage(content=prompt)],\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "990bfb73-bf14-4e6b-9d82-c15a8e8297d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query: dict):\n",
    "    if isinstance(query, dict):\n",
    "        query = query.get(\"question\", \"\")\n",
    "    elif not isinstance(query, str):\n",
    "        raise ValueError(\"Query must be a string or a dictionary with a 'question' key.\")\n",
    "        \n",
    "    search_results = rrf_search(query=query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cbdc0002-c5f1-4a92-9188-7e609c3746d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abdeen Palace in Cairo served as the **royal residence** until the Egyptian monarchy was deposed in **1952**.\n"
     ]
    }
   ],
   "source": [
    "answer_llm = rag(ground_truth[10])\n",
    "print(answer_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1ed8908b-08da-4f4c-b846-f2a9d43352dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0417 31.2483 4 Abdeen Palace . About 1 km east of Midan El-Tahrir, it was the royal residence until the Egyptian monarchy was deposed in 1952. ( updated Jan 2018 )\n"
     ]
    }
   ],
   "source": [
    "answer_org = doc_idx['91c82200']['text']\n",
    "print(answer_org)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842c5d30-96ba-413e-b3a4-e8e955b88d76",
   "metadata": {},
   "source": [
    "# Cosine similarity metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6208884d-057b-42bd-8524-f4c748d9a1db",
   "metadata": {},
   "source": [
    "## Using mistral-medium-2508\n",
    "Premier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0bb41a6e-f395-4d1f-9cd4-f03578a9f19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8076176"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_llm = model.encode(answer_llm)\n",
    "v_org = model.encode(answer_org)\n",
    "\n",
    "v_llm.dot(v_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed88df69-163a-4189-8a39-d337dee44cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326db335-223d-4216-aba7-367204a68cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 2685/2715 [00:49<00:01, 17.14it/s]"
     ]
    }
   ],
   "source": [
    "for i, rec in enumerate(tqdm(ground_truth)):\n",
    "    if i in answers:\n",
    "        continue\n",
    "\n",
    "    answer_llm = rag(rec)\n",
    "    doc_id = rec['id']\n",
    "    original_doc = doc_idx[doc_id]\n",
    "    answer_org = original_doc['text']\n",
    "\n",
    "    answers[i] = {\n",
    "        'answer_llm': answer_llm,\n",
    "        'answer_org': answer_org,\n",
    "        'document': doc_id,\n",
    "        'question': rec['question'],\n",
    "        'city': rec['city'],\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a130d0-12d8-421b-b08d-1b9807b7c44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30726ce-2744-4b89-8f80-f6ccdc98a954",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_mistral_medium = [None] * len(ground_truth)\n",
    "\n",
    "for i, val in answers.items():\n",
    "    results_mistral_medium[i] = val.copy()\n",
    "    results_mistral_medium[i].update(ground_truth[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ae67fa3-3302-4483-a199-48ad00899901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73d0d365-c04c-42c9-83d9-8d1ebdef69ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mistral_medium = pd.DataFrame(results_mistral_medium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e31b50da-1c5e-4009-8b29-c0ecc90e3c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_FOLDER = \"../data/result\"\n",
    "os.makedirs(RESULT_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679f3d77-e681-46a0-8905-fe3f0b7f4fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mistral_medium.to_csv(f\"{RESULT_FOLDER}/results-mistral_medium.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "80fbdf7d-e760-486e-b59c-2e115e630ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_org</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>city</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The name of the oldest known pyramid in Dahshu...</td>\n",
       "      <td>29.8 31.233333 1 Dahshur Pyramids . For a cont...</td>\n",
       "      <td>f7845786</td>\n",
       "      <td>What is the name of the oldest known pyramid i...</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>f7845786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The **Red Pyramid** in Dahshur has an entrance...</td>\n",
       "      <td>29.8 31.233333 1 Dahshur Pyramids . For a cont...</td>\n",
       "      <td>f7845786</td>\n",
       "      <td>Which pyramid in Dahshur has an entrance to th...</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>f7845786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Based on the provided **CONTEXT**, the distinc...</td>\n",
       "      <td>29.8 31.233333 1 Dahshur Pyramids . For a cont...</td>\n",
       "      <td>f7845786</td>\n",
       "      <td>What is the distinctive feature of the Bent Py...</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>f7845786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Based on the provided **CONTEXT**, the followi...</td>\n",
       "      <td>29.8 31.233333 1 Dahshur Pyramids . For a cont...</td>\n",
       "      <td>f7845786</td>\n",
       "      <td>How many pyramids are mentioned to be in the D...</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>f7845786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Based on the **CONTEXT**, the atmosphere aroun...</td>\n",
       "      <td>29.8 31.233333 1 Dahshur Pyramids . For a cont...</td>\n",
       "      <td>f7845786</td>\n",
       "      <td>What is the atmosphere around Dahshur Pyramids...</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>f7845786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          answer_llm  \\\n",
       "0  The name of the oldest known pyramid in Dahshu...   \n",
       "1  The **Red Pyramid** in Dahshur has an entrance...   \n",
       "2  Based on the provided **CONTEXT**, the distinc...   \n",
       "3  Based on the provided **CONTEXT**, the followi...   \n",
       "4  Based on the **CONTEXT**, the atmosphere aroun...   \n",
       "\n",
       "                                          answer_org  document  \\\n",
       "0  29.8 31.233333 1 Dahshur Pyramids . For a cont...  f7845786   \n",
       "1  29.8 31.233333 1 Dahshur Pyramids . For a cont...  f7845786   \n",
       "2  29.8 31.233333 1 Dahshur Pyramids . For a cont...  f7845786   \n",
       "3  29.8 31.233333 1 Dahshur Pyramids . For a cont...  f7845786   \n",
       "4  29.8 31.233333 1 Dahshur Pyramids . For a cont...  f7845786   \n",
       "\n",
       "                                            question   city        id  \n",
       "0  What is the name of the oldest known pyramid i...  Cairo  f7845786  \n",
       "1  Which pyramid in Dahshur has an entrance to th...  Cairo  f7845786  \n",
       "2  What is the distinctive feature of the Bent Py...  Cairo  f7845786  \n",
       "3  How many pyramids are mentioned to be in the D...  Cairo  f7845786  \n",
       "4  What is the atmosphere around Dahshur Pyramids...  Cairo  f7845786  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "299beb03-519b-408c-a803-a6b9895bba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_df = pd.read_csv(f\"{RESULT_FOLDER}/results-mistral_medium.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342b176a-f09b-4c5f-af42-9f501dc4f179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58fc9357-19cf-433e-a9fc-1740b0c09c78",
   "metadata": {},
   "source": [
    "## mistral-small-2506\n",
    "Open model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47a1b3fd-a0c2-4ecd-941b-0ad48e01f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = llm_client.chat.complete(\n",
    "        model=\"open-mixtral-8x7b\",\n",
    "        messages=[UserMessage(content=prompt)],\n",
    "    )\n",
    "\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0e2211d-4ca5-4d36-8fa3-7a7015a6942e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The purpose of Abdeen Palace in Cairo until 1952 was as the royal residence.\n"
     ]
    }
   ],
   "source": [
    "answer_llm = rag(ground_truth[10])\n",
    "print(answer_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ed0c132-5ff9-4328-bc55-050b39f6e471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0417 31.2483 4 Abdeen Palace . About 1 km east of Midan El-Tahrir, it was the royal residence until the Egyptian monarchy was deposed in 1952. ( updated Jan 2018 )\n"
     ]
    }
   ],
   "source": [
    "answer_org = doc_idx['91c82200']['text']\n",
    "print(answer_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a17e994c-7005-4dff-98af-a66f16ac8aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71375585"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_llm = model.encode(answer_llm)\n",
    "v_org = model.encode(answer_org)\n",
    "\n",
    "v_llm.dot(v_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9329f97c-ac78-4cfd-a07b-d19798681675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "pool = ThreadPoolExecutor(max_workers=6)\n",
    "\n",
    "def map_progress(pool, seq, f):\n",
    "    results = []\n",
    "\n",
    "    with tqdm(total=len(seq)) as progress:\n",
    "        futures = []\n",
    "\n",
    "        for el in seq:\n",
    "            future = pool.submit(f, el)\n",
    "            future.add_done_callback(lambda p: progress.update())\n",
    "            futures.append(future)\n",
    "\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27ac348a-d0a5-48ac-87ac-f4bb14218247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_record(rec):\n",
    "    model = \"open-mixtral-8x7b\"\n",
    "    answer_llm = rag(rec)\n",
    "    \n",
    "    doc_id = rec['id']\n",
    "    original_doc = doc_idx[doc_id]\n",
    "    answer_org = original_doc['text']\n",
    "\n",
    "    return {\n",
    "        'answer_llm': answer_llm,\n",
    "        'answer_org': answer_org,\n",
    "        'document': doc_id,\n",
    "        'question': rec['question'],\n",
    "        'city': rec['city'],\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba93ce8f-a44c-4509-a0af-65df77d7610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_mistral_big = map_progress(pool, ground_truth, process_record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97d34aa3-60f6-4e8c-8178-5c45f92f0368",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_big = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab86e037-4427-4b56-9ec8-3e1f177d35ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2715/2715 [00:51<00:00, 53.11it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, rec in enumerate(tqdm(ground_truth)):\n",
    "    if i in answers_big:\n",
    "        continue\n",
    "\n",
    "    answer_llm = rag(rec)\n",
    "    doc_id = rec['id']\n",
    "    original_doc = doc_idx[doc_id]\n",
    "    answer_org = original_doc['text']\n",
    "\n",
    "    answers_big[i] = {\n",
    "        'answer_llm': answer_llm,\n",
    "        'answer_org': answer_org,\n",
    "        'document': doc_id,\n",
    "        'question': rec['question'],\n",
    "        'city': rec['city'],\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "64d27b3a-c49a-44ab-936c-2fa8a277f263",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_mistral_big = [None] * len(ground_truth)\n",
    "\n",
    "for i, val in answers_big.items():\n",
    "    results_mistral_big[i] = val.copy()\n",
    "    results_mistral_big[i].update(ground_truth[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6f8b9b68-ce5c-44a7-a1fc-d9177ebaf3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mistral_big = pd.DataFrame(results_mistral_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2d567b8d-2043-46c9-8f99-8ed4f53d4fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mistral_big.to_csv(f\"{RESULT_FOLDER}/results-mistral_big.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8402ab12-6da6-45b5-a3c4-92f00a46c750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open 'f../data/result/results-mistral_big.csv' for reading: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!head f\"{RESULT_FOLDER}/results-mistral_big.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a1a712-e046-4eaa-b990-30464ef0ab9a",
   "metadata": {},
   "source": [
    "# Code for Evalutaion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc77f81-d7b0-4339-adbb-1a22be3ee15f",
   "metadata": {},
   "source": [
    "# Cosine smiliartity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea9c3a1d-076b-4056-9289-6f474b32e5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_medium = medium_df.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0cb21fa2-61f7-4f92-b2d6-ff87c50129eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "record = results_medium[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "df20a385-45de-4fbb-8f82-720cd8a3526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(record):\n",
    "\n",
    "    answer_llm = record[\"answer_llm\"]\n",
    "    answer_org = record[\"answer_org\"]\n",
    "    v_llm = model.encode(answer_llm)\n",
    "    v_org = model.encode(answer_org)\n",
    "    \n",
    "    return v_llm.dot(v_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1fda42d8-cffe-4329-91c4-9054594c62d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2715/2715 [04:11<00:00, 10.81it/s]\n"
     ]
    }
   ],
   "source": [
    "similarity = []\n",
    "\n",
    "for record in tqdm(results_medium):\n",
    "    sim = compute_similarity(record)\n",
    "    similarity.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "52ca0353-1a39-445a-99c8-604910d29a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_df['cosine'] = similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dfbe4653-2e81-499e-9fdc-c83f43e7850a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_org</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>city</th>\n",
       "      <th>id</th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The name of the oldest known pyramid in Dahshu...</td>\n",
       "      <td>29.8 31.233333 1 Dahshur Pyramids . For a cont...</td>\n",
       "      <td>f7845786</td>\n",
       "      <td>What is the name of the oldest known pyramid i...</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>f7845786</td>\n",
       "      <td>0.744416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The **Red Pyramid** in Dahshur has an entrance...</td>\n",
       "      <td>29.8 31.233333 1 Dahshur Pyramids . For a cont...</td>\n",
       "      <td>f7845786</td>\n",
       "      <td>Which pyramid in Dahshur has an entrance to th...</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>f7845786</td>\n",
       "      <td>0.649594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Based on the provided **CONTEXT**, the distinc...</td>\n",
       "      <td>29.8 31.233333 1 Dahshur Pyramids . For a cont...</td>\n",
       "      <td>f7845786</td>\n",
       "      <td>What is the distinctive feature of the Bent Py...</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>f7845786</td>\n",
       "      <td>0.465671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Based on the provided **CONTEXT**, the followi...</td>\n",
       "      <td>29.8 31.233333 1 Dahshur Pyramids . For a cont...</td>\n",
       "      <td>f7845786</td>\n",
       "      <td>How many pyramids are mentioned to be in the D...</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>f7845786</td>\n",
       "      <td>0.695287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Based on the **CONTEXT**, the atmosphere aroun...</td>\n",
       "      <td>29.8 31.233333 1 Dahshur Pyramids . For a cont...</td>\n",
       "      <td>f7845786</td>\n",
       "      <td>What is the atmosphere around Dahshur Pyramids...</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>f7845786</td>\n",
       "      <td>0.734467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2710</th>\n",
       "      <td>Based on the provided **CONTEXT**, here is the...</td>\n",
       "      <td>₩15,000–35,000</td>\n",
       "      <td>feb11863</td>\n",
       "      <td>What is the estimated price range for dining o...</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>feb11863</td>\n",
       "      <td>0.492113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2711</th>\n",
       "      <td>Based on the **CONTEXT**, you **will not** nee...</td>\n",
       "      <td>₩15,000–35,000</td>\n",
       "      <td>feb11863</td>\n",
       "      <td>Will I need more than ₩35,000 for a meal in Se...</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>feb11863</td>\n",
       "      <td>0.547441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>Yes, you can easily find a meal for under ₩15,...</td>\n",
       "      <td>₩15,000–35,000</td>\n",
       "      <td>feb11863</td>\n",
       "      <td>Can I find a meal for under ₩15,000 in Seoul?</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>feb11863</td>\n",
       "      <td>0.481077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>Based on the **CONTEXT**, the **lowest amount ...</td>\n",
       "      <td>₩15,000–35,000</td>\n",
       "      <td>feb11863</td>\n",
       "      <td>What is the lowest amount I can expect to spen...</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>feb11863</td>\n",
       "      <td>0.494290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>Based on the provided **CONTEXT**, there is **...</td>\n",
       "      <td>₩15,000–35,000</td>\n",
       "      <td>feb11863</td>\n",
       "      <td>What is the approximate high-end cost for a me...</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>feb11863</td>\n",
       "      <td>0.454236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2715 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             answer_llm  \\\n",
       "0     The name of the oldest known pyramid in Dahshu...   \n",
       "1     The **Red Pyramid** in Dahshur has an entrance...   \n",
       "2     Based on the provided **CONTEXT**, the distinc...   \n",
       "3     Based on the provided **CONTEXT**, the followi...   \n",
       "4     Based on the **CONTEXT**, the atmosphere aroun...   \n",
       "...                                                 ...   \n",
       "2710  Based on the provided **CONTEXT**, here is the...   \n",
       "2711  Based on the **CONTEXT**, you **will not** nee...   \n",
       "2712  Yes, you can easily find a meal for under ₩15,...   \n",
       "2713  Based on the **CONTEXT**, the **lowest amount ...   \n",
       "2714  Based on the provided **CONTEXT**, there is **...   \n",
       "\n",
       "                                             answer_org  document  \\\n",
       "0     29.8 31.233333 1 Dahshur Pyramids . For a cont...  f7845786   \n",
       "1     29.8 31.233333 1 Dahshur Pyramids . For a cont...  f7845786   \n",
       "2     29.8 31.233333 1 Dahshur Pyramids . For a cont...  f7845786   \n",
       "3     29.8 31.233333 1 Dahshur Pyramids . For a cont...  f7845786   \n",
       "4     29.8 31.233333 1 Dahshur Pyramids . For a cont...  f7845786   \n",
       "...                                                 ...       ...   \n",
       "2710                                     ₩15,000–35,000  feb11863   \n",
       "2711                                     ₩15,000–35,000  feb11863   \n",
       "2712                                     ₩15,000–35,000  feb11863   \n",
       "2713                                     ₩15,000–35,000  feb11863   \n",
       "2714                                     ₩15,000–35,000  feb11863   \n",
       "\n",
       "                                               question   city        id  \\\n",
       "0     What is the name of the oldest known pyramid i...  Cairo  f7845786   \n",
       "1     Which pyramid in Dahshur has an entrance to th...  Cairo  f7845786   \n",
       "2     What is the distinctive feature of the Bent Py...  Cairo  f7845786   \n",
       "3     How many pyramids are mentioned to be in the D...  Cairo  f7845786   \n",
       "4     What is the atmosphere around Dahshur Pyramids...  Cairo  f7845786   \n",
       "...                                                 ...    ...       ...   \n",
       "2710  What is the estimated price range for dining o...  Seoul  feb11863   \n",
       "2711  Will I need more than ₩35,000 for a meal in Se...  Seoul  feb11863   \n",
       "2712      Can I find a meal for under ₩15,000 in Seoul?  Seoul  feb11863   \n",
       "2713  What is the lowest amount I can expect to spen...  Seoul  feb11863   \n",
       "2714  What is the approximate high-end cost for a me...  Seoul  feb11863   \n",
       "\n",
       "        cosine  \n",
       "0     0.744416  \n",
       "1     0.649594  \n",
       "2     0.465671  \n",
       "3     0.695287  \n",
       "4     0.734467  \n",
       "...        ...  \n",
       "2710  0.492113  \n",
       "2711  0.547441  \n",
       "2712  0.481077  \n",
       "2713  0.494290  \n",
       "2714  0.454236  \n",
       "\n",
       "[2715 rows x 7 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "26fa0ce1-5575-4096-8e75-5891950683c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_llm': 'The Vatican is located in the **Vatican** area of Rome. It is described as the **Papal City State** and its surrounding Italian neighborhood.',\n",
       " 'answer_org': 'Modern Centre Old Rome Vatican Colosseo North Centre Trastevere',\n",
       " 'document': '913cf7c3',\n",
       " 'question': 'Which part of Rome is the Vatican located in?',\n",
       " 'city': 'Rome',\n",
       " 'id': '913cf7c3',\n",
       " 'cosine': 0.5046500563621521}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_df.iloc[2000].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4e451183-e523-43b9-b014-9ca973dee09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2715.000000\n",
       "mean        0.674111\n",
       "std         0.176574\n",
       "min        -0.063424\n",
       "25%         0.609269\n",
       "50%         0.707447\n",
       "75%         0.788128\n",
       "max         1.000000\n",
       "Name: cosine, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_df['cosine'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c941a854-efad-41cd-9f2c-0382f1731408",
   "metadata": {},
   "source": [
    "## Add rouge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f9539d6b-5e6f-42fe-aff0-221abc1dbba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3b9bb903-ea40-4a75-9b14-f78fd126812f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_score = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f127242e-8751-400e-9682-a372f0b24b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = medium_df.iloc[2000]\n",
    "scores = rouge_score.get_scores(r.answer_llm, r.answer_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "24ee1233-2e33-4e7e-b6d1-ddb6586bc5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'r': 0.25, 'p': 0.09523809523809523, 'f': 0.13793103048751498},\n",
       "  'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "  'rouge-l': {'r': 0.125,\n",
       "   'p': 0.047619047619047616,\n",
       "   'f': 0.06896551324613578}}]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "64fed2ad-ee5e-4e03-94e4-2bf85ca624e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2715/2715 [00:05<00:00, 538.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average Rouge-1 F1 for the whole DF:  0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rouge_sim = []\n",
    "\n",
    "for r in tqdm(results_medium):\n",
    "    scores = rouge_score.get_scores(r['answer_llm'], r['answer_org'])\n",
    "    rouge_sim.append(scores[0]['rouge-1']['f'])\n",
    "    \n",
    "avg_rouge_smiliarity=np.mean(rouge_sim)\n",
    "print(f\"The average Rouge-1 F1 for the whole DF: \",avg_rouge_smiliarity.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2627b99a-890c-4dc5-8aaa-df795a52f212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2715/2715 [00:04<00:00, 545.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average Rouge-1 F1 for the whole DF:  0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rouge_sim = []\n",
    "\n",
    "for r in tqdm(results_medium):\n",
    "    scores = rouge_score.get_scores(r['answer_llm'], r['answer_org'])\n",
    "    rouge_sim.append(scores[0]['rouge-l']['f'])\n",
    "    \n",
    "avg_rouge_smiliarity=np.mean(rouge_sim)\n",
    "print(f\"The average rouge-l F1 for the whole DF: \",avg_rouge_smiliarity.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1bbf493f-7c4d-4768-9797-ed2b8022679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0a11d573-5041-41cf-9e3c-b5d47e6e0cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(df_gpt4o['cosine'], label='4o')\n",
    "# sns.distplot(df_gpt4o_mini['cosine'], label='4o-mini')\n",
    "\n",
    "# plt.title(\"RAG LLM performance\")\n",
    "# plt.xlabel(\"A->Q->A' Cosine Similarity\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0136c326-4dc9-4899-9ff3-7dadb5105731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3007/829340080.py:1: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(medium_df['cosine'], label='medium')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='cosine', ylabel='Density'>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(medium_df['cosine'], label='medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6620bdcc-5e61-41ed-b626-ad576fabf2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try the code for other models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbea9aa-c549-4fde-be26-3831db716c67",
   "metadata": {},
   "source": [
    "# LLM as a judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7c303f7f-76b4-4977-8d9d-56294b9f1695",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1_template = \"\"\"\n",
    "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
    "Your task is to analyze the relevance of the generated answer compared to the original answer provided.\n",
    "Based on the relevance and similarity of the generated answer to the original answer, you will classify\n",
    "it as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Original Answer: {answer_org}\n",
    "Generated Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the original\n",
    "answer and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt2_template = \"\"\"\n",
    "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
    "Your task is to analyze the relevance of the generated answer to the given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8ce452ef-f696-45e6-a537-95bf06b40106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_org</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>city</th>\n",
       "      <th>id</th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The name of the oldest known pyramid in Dahshu...</td>\n",
       "      <td>29.8 31.233333 1 Dahshur Pyramids . For a cont...</td>\n",
       "      <td>f7845786</td>\n",
       "      <td>What is the name of the oldest known pyramid i...</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>f7845786</td>\n",
       "      <td>0.744416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The **Red Pyramid** in Dahshur has an entrance...</td>\n",
       "      <td>29.8 31.233333 1 Dahshur Pyramids . For a cont...</td>\n",
       "      <td>f7845786</td>\n",
       "      <td>Which pyramid in Dahshur has an entrance to th...</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>f7845786</td>\n",
       "      <td>0.649594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Based on the provided **CONTEXT**, the distinc...</td>\n",
       "      <td>29.8 31.233333 1 Dahshur Pyramids . For a cont...</td>\n",
       "      <td>f7845786</td>\n",
       "      <td>What is the distinctive feature of the Bent Py...</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>f7845786</td>\n",
       "      <td>0.465671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Based on the provided **CONTEXT**, the followi...</td>\n",
       "      <td>29.8 31.233333 1 Dahshur Pyramids . For a cont...</td>\n",
       "      <td>f7845786</td>\n",
       "      <td>How many pyramids are mentioned to be in the D...</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>f7845786</td>\n",
       "      <td>0.695287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Based on the **CONTEXT**, the atmosphere aroun...</td>\n",
       "      <td>29.8 31.233333 1 Dahshur Pyramids . For a cont...</td>\n",
       "      <td>f7845786</td>\n",
       "      <td>What is the atmosphere around Dahshur Pyramids...</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>f7845786</td>\n",
       "      <td>0.734467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2710</th>\n",
       "      <td>Based on the provided **CONTEXT**, here is the...</td>\n",
       "      <td>₩15,000–35,000</td>\n",
       "      <td>feb11863</td>\n",
       "      <td>What is the estimated price range for dining o...</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>feb11863</td>\n",
       "      <td>0.492113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2711</th>\n",
       "      <td>Based on the **CONTEXT**, you **will not** nee...</td>\n",
       "      <td>₩15,000–35,000</td>\n",
       "      <td>feb11863</td>\n",
       "      <td>Will I need more than ₩35,000 for a meal in Se...</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>feb11863</td>\n",
       "      <td>0.547441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>Yes, you can easily find a meal for under ₩15,...</td>\n",
       "      <td>₩15,000–35,000</td>\n",
       "      <td>feb11863</td>\n",
       "      <td>Can I find a meal for under ₩15,000 in Seoul?</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>feb11863</td>\n",
       "      <td>0.481077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>Based on the **CONTEXT**, the **lowest amount ...</td>\n",
       "      <td>₩15,000–35,000</td>\n",
       "      <td>feb11863</td>\n",
       "      <td>What is the lowest amount I can expect to spen...</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>feb11863</td>\n",
       "      <td>0.494290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>Based on the provided **CONTEXT**, there is **...</td>\n",
       "      <td>₩15,000–35,000</td>\n",
       "      <td>feb11863</td>\n",
       "      <td>What is the approximate high-end cost for a me...</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>feb11863</td>\n",
       "      <td>0.454236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2715 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             answer_llm  \\\n",
       "0     The name of the oldest known pyramid in Dahshu...   \n",
       "1     The **Red Pyramid** in Dahshur has an entrance...   \n",
       "2     Based on the provided **CONTEXT**, the distinc...   \n",
       "3     Based on the provided **CONTEXT**, the followi...   \n",
       "4     Based on the **CONTEXT**, the atmosphere aroun...   \n",
       "...                                                 ...   \n",
       "2710  Based on the provided **CONTEXT**, here is the...   \n",
       "2711  Based on the **CONTEXT**, you **will not** nee...   \n",
       "2712  Yes, you can easily find a meal for under ₩15,...   \n",
       "2713  Based on the **CONTEXT**, the **lowest amount ...   \n",
       "2714  Based on the provided **CONTEXT**, there is **...   \n",
       "\n",
       "                                             answer_org  document  \\\n",
       "0     29.8 31.233333 1 Dahshur Pyramids . For a cont...  f7845786   \n",
       "1     29.8 31.233333 1 Dahshur Pyramids . For a cont...  f7845786   \n",
       "2     29.8 31.233333 1 Dahshur Pyramids . For a cont...  f7845786   \n",
       "3     29.8 31.233333 1 Dahshur Pyramids . For a cont...  f7845786   \n",
       "4     29.8 31.233333 1 Dahshur Pyramids . For a cont...  f7845786   \n",
       "...                                                 ...       ...   \n",
       "2710                                     ₩15,000–35,000  feb11863   \n",
       "2711                                     ₩15,000–35,000  feb11863   \n",
       "2712                                     ₩15,000–35,000  feb11863   \n",
       "2713                                     ₩15,000–35,000  feb11863   \n",
       "2714                                     ₩15,000–35,000  feb11863   \n",
       "\n",
       "                                               question   city        id  \\\n",
       "0     What is the name of the oldest known pyramid i...  Cairo  f7845786   \n",
       "1     Which pyramid in Dahshur has an entrance to th...  Cairo  f7845786   \n",
       "2     What is the distinctive feature of the Bent Py...  Cairo  f7845786   \n",
       "3     How many pyramids are mentioned to be in the D...  Cairo  f7845786   \n",
       "4     What is the atmosphere around Dahshur Pyramids...  Cairo  f7845786   \n",
       "...                                                 ...    ...       ...   \n",
       "2710  What is the estimated price range for dining o...  Seoul  feb11863   \n",
       "2711  Will I need more than ₩35,000 for a meal in Se...  Seoul  feb11863   \n",
       "2712      Can I find a meal for under ₩15,000 in Seoul?  Seoul  feb11863   \n",
       "2713  What is the lowest amount I can expect to spen...  Seoul  feb11863   \n",
       "2714  What is the approximate high-end cost for a me...  Seoul  feb11863   \n",
       "\n",
       "        cosine  \n",
       "0     0.744416  \n",
       "1     0.649594  \n",
       "2     0.465671  \n",
       "3     0.695287  \n",
       "4     0.734467  \n",
       "...        ...  \n",
       "2710  0.492113  \n",
       "2711  0.547441  \n",
       "2712  0.481077  \n",
       "2713  0.494290  \n",
       "2714  0.454236  \n",
       "\n",
       "[2715 rows x 7 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9b763957-58c9-465d-9097-19b6d5f32254",
   "metadata": {},
   "outputs": [],
   "source": [
    "record = results_medium[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4d5305a6-f1c5-4db6-b1f7-e64030c2b85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
      "Your task is to analyze the relevance of the generated answer compared to the original answer provided.\n",
      "Based on the relevance and similarity of the generated answer to the original answer, you will classify\n",
      "it as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Original Answer: Modern Centre Old Rome Vatican Colosseo North Centre Trastevere\n",
      "Generated Question: Which part of Rome is the Vatican located in?\n",
      "Generated Answer: The Vatican is located in the **Vatican** area of Rome. It is described as the **Papal City State** and its surrounding Italian neighborhood.\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the original\n",
      "answer and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt  = prompt1_template.format(**record)\n",
    "print(prompt)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9b98e8-f349-4617-b582-5ba0991c5d9f",
   "metadata": {},
   "source": [
    "## Define the model that has the best perfromance to parce that one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bec4912c-c18f-426c-95c6-3e204e35b692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = llm_client.chat.complete(\n",
    "        model=\"open-mixtral-8x7b\",\n",
    "        messages=[UserMessage(content=prompt)],\n",
    "    )\n",
    "\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7e784276-950c-4203-8c4b-f28b389dfdef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"Relevance\": \"PARTLY_RELEVANT\",\\n  \"Explanation\": \"The generated answer correctly identifies the location of the Vatican in Rome, but it does not match the exact phrasing or provide the same level of detail as the original answer. The generated answer refers to the Vatican as a \\'city-state\\' and mentions its \\'Italian neighborhood\\', while the original answer simply refers to it as \\'Vatican\\'. However, the key point of the answer is still relevant to the original answer.\"\\n}'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = llm(prompt)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7ee26434-b20a-4f09-8aec-cacf46462c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d3a89ced-2e70-45e1-a5d5-30475d474cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Relevance': 'PARTLY_RELEVANT',\n",
       " 'Explanation': \"The generated answer correctly identifies the location of the Vatican in Rome, but it does not match the exact phrasing or provide the same level of detail as the original answer. The generated answer refers to the Vatican as a 'city-state' and mentions its 'Italian neighborhood', while the original answer simply refers to it as 'Vatican'. However, the key point of the answer is still relevant to the original answer.\"}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "0c2ac4c8-2519-4da6-a35f-dbb9bea71a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "0e9c1c20-101b-421e-b634-764dd918eb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████████████▏                                                                                                                           | 278/2715 [06:00<52:35,  1.30s/it]\n"
     ]
    },
    {
     "ename": "SDKError",
     "evalue": "API error occurred: Status 429\n{\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mSDKError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[202]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m tqdm(results_medium):\n\u001b[32m      3\u001b[39m     prompt = prompt1_template.format(**record)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     evaluation = \u001b[43mllm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     evaluations.append(evaluation)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[141]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mllm\u001b[39m\u001b[34m(prompt)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mllm\u001b[39m(prompt):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     response = \u001b[43mllm_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# model= \"open-mistral-7b\",\u001b[39;49;00m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mopen-mixtral-8x7b\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mUserMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.choices[\u001b[32m0\u001b[39m].message.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Travel Assistant/Musafir/venv/lib/python3.12/site-packages/mistralai/chat.py:247\u001b[39m, in \u001b[36mChat.complete\u001b[39m\u001b[34m(self, model, messages, temperature, top_p, max_tokens, stream, stop, random_seed, response_format, tools, tool_choice, presence_penalty, frequency_penalty, n, prediction, parallel_tool_calls, prompt_mode, safe_prompt, retries, server_url, timeout_ms, http_headers)\u001b[39m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m utils.match_response(http_res, \u001b[33m\"\u001b[39m\u001b[33m4XX\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    246\u001b[39m     http_res_text = utils.stream_to_text(http_res)\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m models.SDKError(\n\u001b[32m    248\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAPI error occurred\u001b[39m\u001b[33m\"\u001b[39m, http_res.status_code, http_res_text, http_res\n\u001b[32m    249\u001b[39m     )\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m utils.match_response(http_res, \u001b[33m\"\u001b[39m\u001b[33m5XX\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    251\u001b[39m     http_res_text = utils.stream_to_text(http_res)\n",
      "\u001b[31mSDKError\u001b[39m: API error occurred: Status 429\n{\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}"
     ]
    }
   ],
   "source": [
    "for record in tqdm(results_medium):\n",
    "    \n",
    "    prompt = prompt1_template.format(**record)\n",
    "    evaluation = llm(prompt)\n",
    "    evaluations.append(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0df6d6a9-3611-4f46-b78a-f431e48e1540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "543"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "80155148-9a34-466c-8531-411aa55b1f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_evaluations = []\n",
    "\n",
    "# for i, str_eval in enumerate(evaluations):\n",
    "#     json_eval = json.loads(str_eval)\n",
    "#     json_evaluations.append(json_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "3772e4c5-5762-4b05-83bd-d9a6cc9444f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 0,\n",
       "  'record_id': 'f7845786',\n",
       "  'Relevance': 'RELEVANT',\n",
       "  'Explanation': 'The generated answer correctly identifies the name of the oldest known pyramid in Dahshur as the Red Pyramid, which is consistent with the information provided in the original answer.'},\n",
       " {'index': 5,\n",
       "  'record_id': 'fca551b1',\n",
       "  'Relevance': 'RELEVANT',\n",
       "  'Explanation': 'The generated answer directly provides the coordinates of Al-Azhar Park, which is the same information as the original answer.'}]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_evaluations = []\n",
    "\n",
    "for e in evaluations:\n",
    "\n",
    "    eval_json = json.loads(e[\"evaluation\"])\n",
    "    parsed_evaluations.append({\n",
    "        \"index\": e[\"index\"],\n",
    "        \"record_id\": e[\"record_id\"],\n",
    "        \"Relevance\": eval_json.get(\"Relevance\"),\n",
    "        \"Explanation\": eval_json.get(\"Explanation\")\n",
    "    })\n",
    "\n",
    "\n",
    "parsed_evaluations[:2]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "202abb79-6989-415d-aeb0-1a4afa35f922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "543"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parsed_evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c5e5b9e2-7a34-4ccd-bad8-1fa43e930490",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations = pd.DataFrame(evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7d00884b-cb0b-4420-a5a8-8398e4e1482d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>record_id</th>\n",
       "      <th>evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>f7845786</td>\n",
       "      <td>{\\n  \"Relevance\": \"RELEVANT\",\\n  \"Explanation\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>fca551b1</td>\n",
       "      <td>{\\n  \"Relevance\": \"RELEVANT\",\\n  \"Explanation\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>91c82200</td>\n",
       "      <td>{\\n  \"Relevance\": \"RELEVANT\",\\n  \"Explanation\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>a4b7a503</td>\n",
       "      <td>{\\n  \"Relevance\": \"PARTLY_RELEVANT\",\\n  \"Expla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>84d1da2a</td>\n",
       "      <td>{\\n  \"Relevance\": \"RELEVANT\",\\n  \"Explanation\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>2690</td>\n",
       "      <td>86841f08</td>\n",
       "      <td>{\\n  \"Relevance\": \"RELEVANT\",\\n  \"Explanation\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>2695</td>\n",
       "      <td>6f81da78</td>\n",
       "      <td>{\\n  \"Relevance\": \"PARTLY_RELEVANT\",\\n  \"Expla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>2700</td>\n",
       "      <td>2bb90712</td>\n",
       "      <td>{\\n  \"Relevance\": \"PARTLY_RELEVANT\",\\n  \"Expla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>2705</td>\n",
       "      <td>7a40c5e2</td>\n",
       "      <td>{\\n  \"Relevance\": \"PARTLY_RELEVANT\",\\n  \"Expla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>2710</td>\n",
       "      <td>feb11863</td>\n",
       "      <td>{\\n  \"Relevance\": \"PARTLY_RELEVANT\",\\n  \"Expla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>543 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index record_id                                         evaluation\n",
       "0        0  f7845786  {\\n  \"Relevance\": \"RELEVANT\",\\n  \"Explanation\"...\n",
       "1        5  fca551b1  {\\n  \"Relevance\": \"RELEVANT\",\\n  \"Explanation\"...\n",
       "2       10  91c82200  {\\n  \"Relevance\": \"RELEVANT\",\\n  \"Explanation\"...\n",
       "3       15  a4b7a503  {\\n  \"Relevance\": \"PARTLY_RELEVANT\",\\n  \"Expla...\n",
       "4       20  84d1da2a  {\\n  \"Relevance\": \"RELEVANT\",\\n  \"Explanation\"...\n",
       "..     ...       ...                                                ...\n",
       "538   2690  86841f08  {\\n  \"Relevance\": \"RELEVANT\",\\n  \"Explanation\"...\n",
       "539   2695  6f81da78  {\\n  \"Relevance\": \"PARTLY_RELEVANT\",\\n  \"Expla...\n",
       "540   2700  2bb90712  {\\n  \"Relevance\": \"PARTLY_RELEVANT\",\\n  \"Expla...\n",
       "541   2705  7a40c5e2  {\\n  \"Relevance\": \"PARTLY_RELEVANT\",\\n  \"Expla...\n",
       "542   2710  feb11863  {\\n  \"Relevance\": \"PARTLY_RELEVANT\",\\n  \"Expla...\n",
       "\n",
       "[543 rows x 3 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9e19819b-f084-4bc6-a1cb-9c3f2d49d442",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Relevance'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_3007/3822601223.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_evaluations.Relevance.value_counts()\n",
      "\u001b[32m/mnt/d/Travel Assistant/Musafir/venv/lib/python3.12/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6314\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m name \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m self._accessors\n\u001b[32m   6315\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m self._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6316\u001b[39m         ):\n\u001b[32m   6317\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self[name]\n\u001b[32m-> \u001b[39m\u001b[32m6318\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m object.__getattribute__(self, name)\n",
      "\u001b[31mAttributeError\u001b[39m: 'DataFrame' object has no attribute 'Relevance'"
     ]
    }
   ],
   "source": [
    "df_evaluations.Relevance.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25e97db-2e9c-407e-9cc2-35d6834f446c",
   "metadata": {},
   "source": [
    "## Second prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01a247f-5d1d-4421-8157-642a5c52c324",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations_2 = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd497561-3557-44e7-b13c-75201d59bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, record in enumerate(tqdm(results_medium)):\n",
    "    if i in evaluations:\n",
    "        continue\n",
    "        \n",
    "    prompt = prompt2_template.format(**record)\n",
    "    evaluation = llm(prompt)\n",
    "    evaluations_2.append(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7414799c-8a8c-4c8d-b258-99297dd0f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_evaluations_2 = []\n",
    "\n",
    "for i, str_eval in enumerate(evaluations_2):\n",
    "    json_eval = json.loads(str_eval)\n",
    "    json_evaluations_2.append(json_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7643ca9c-a3f9-4168-b05a-236394220a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations_2 = pd.DataFrame(json_evaluations_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85f07fe-80cb-4ddd-8f94-33c4ea34a587",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations_2.Relevance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62444875-e707-4ded-b202-44295fde43fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34edebc5-ef5c-484a-9f3b-1981e45b8478",
   "metadata": {},
   "source": [
    "# Saving all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf7f5f1-01e8-472a-aae8-a1c0e958904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations.to_csv('data/evaluations-aqa.csv', index=False)\n",
    "df_evaluations_2.to_csv('data/evaluations-qa.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
